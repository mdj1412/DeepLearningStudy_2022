{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 12-2 char-seq-RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n",
      "x_one_hot_eager tf.Tensor(\n",
      "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "  [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "  [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]], shape=(1, 15, 10), dtype=float32)\n",
      "x_one_hot_numpy [[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "  [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "  [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]]\n",
      "y_one_hot_eager tf.Tensor(\n",
      "[[[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "  [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "  [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]]], shape=(1, 15, 10), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-26 16:24:00.816723: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-08-26 16:24:00.816858: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# Lab 12 Character Sequence RNN\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "sample = \" if you want you\"\n",
    "idx2char = list(set(sample))  # index -> char\n",
    "char2idx = {c: i for i, c in enumerate(idx2char)}  # char -> idex\n",
    "\n",
    "# hyper parameters\n",
    "dic_size = len(char2idx)  # RNN input size (one hot size)\n",
    "hidden_size = len(char2idx)  # RNN output size\n",
    "num_classes = len(char2idx)  # final output size (RNN or softmax, etc.)\n",
    "batch_size = 1  # one sample data, one batch\n",
    "sequence_length = len(sample) - 1  # number of lstm rollings (unit #)\n",
    "learning_rate = 0.1\n",
    "\n",
    "sample_idx = [char2idx[c] for c in sample]  # char to index\n",
    "x_data = [sample_idx[:-1]]  # X data sample (0 ~ n-1) hello: hell\n",
    "y_data = [sample_idx[1:]]   # Y label sample (1 ~ n) hello: ello\n",
    "\n",
    "x_one_hot_eager = tf.one_hot(x_data, num_classes)  # one hot: 1 -> 0 1 0 0 0 0 0 0 0 0\n",
    "x_one_hot_numpy = tf.keras.utils.to_categorical(x_data, num_classes)  # it'll generate numpy array, either way works\n",
    "y_one_hot_eager = tf.one_hot(y_data, num_classes)\n",
    "\n",
    "print(\"x_one_hot_eager\", x_one_hot_eager)\n",
    "print(\"x_one_hot_numpy\", x_one_hot_numpy)\n",
    "print(\"y_one_hot_eager\", y_one_hot_eager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 15, 10)            840       \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 15, 10)           110       \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 950\n",
      "Trainable params: 950\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mindongjun/miniconda3/envs/tf2/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2022-08-26 16:24:02.017577: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-08-26 16:24:02.869122: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-08-26 16:24:03.168032: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-08-26 16:24:06.489316: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 5s 5s/step - loss: 2.2942 - accuracy: 0.2000\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.1280 - accuracy: 0.1333\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.9936 - accuracy: 0.4667\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.8026 - accuracy: 0.4667\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.5331 - accuracy: 0.5333\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.2289 - accuracy: 0.7333\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.9624 - accuracy: 0.8000\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7386 - accuracy: 0.9333\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.5439 - accuracy: 0.9333\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3919 - accuracy: 1.0000\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2857 - accuracy: 1.0000\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2090 - accuracy: 1.0000\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1518 - accuracy: 1.0000\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1088 - accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0779 - accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0555 - accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0397 - accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0286 - accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0210 - accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0157 - accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0119 - accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0092 - accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0072 - accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 9.4968e-04 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.8409e-04 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 8.2622e-04 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 7.7553e-04 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 7.3158e-04 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.9361e-04 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 6.6090e-04 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 6.3265e-04 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 6.0804e-04 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 5.8633e-04 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 5.6693e-04 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.4941e-04 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 5.3349e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x169f49df0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.model = tf.keras.Sequential();\n",
    "\n",
    "# return_sequences : Boolean (default False). Whether to return the last output in the output sequence, or the full sequence.\n",
    "tf.model.add(tf.keras.layers.LSTM(units=num_classes, input_shape=(sequence_length, x_one_hot_eager.shape[2]), return_sequences=True))\n",
    "\n",
    "# tf.keras.layers.TimeDistributed : This wrapper allows to apply a layer to every temporal slice of an input.\n",
    "tf.model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(units=num_classes, activation='softmax')))\n",
    "\n",
    "tf.model.summary()\n",
    "\n",
    "tf.model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(lr=learning_rate), metrics=['accuracy'])\n",
    "\n",
    "# train\n",
    "tf.model.fit(x_one_hot_eager, y_one_hot_eager, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 409ms/step\n",
      "\tPrediction str:  if you want you\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-26 16:24:08.649030: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-08-26 16:24:08.708537: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "predictions = tf.model.predict(x_one_hot_eager)\n",
    "\n",
    "for i, prediction in enumerate(predictions):\n",
    "    # print char using argmax, dict\n",
    "    result_str = [idx2char[c] for c in np.argmax(prediction, axis=1)]\n",
    "    print(\"\\tPrediction str: \", ''.join(result_str))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 ('tf2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7c0a6cafd1d3578584654591a2ba703dcd0177f375c399a413abbbba46e2d79b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
