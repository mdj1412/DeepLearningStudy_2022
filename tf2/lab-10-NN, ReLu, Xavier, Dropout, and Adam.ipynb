{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 10 NN, ReLu, Xavier, Dropout, and Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Softmax classifier for MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train\n",
      "\n",
      "[[[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]]\n",
      "x_test\n",
      "\n",
      "[[[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]]\n",
      "==========================================================\n",
      "x_train\n",
      "\n",
      "[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]]\n",
      "x_test\n",
      "\n",
      "[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "# Lab 7 Learning rate and Evaluation\n",
    "import tensorflow as tf\n",
    "\n",
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "training_epochs = 30\n",
    "nb_classes = 10\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "# load_data mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "print(\"x_train\\n\")\n",
    "print(x_train)\n",
    "print(\"x_test\\n\")\n",
    "print(x_test)\n",
    "\n",
    "# normalizing data\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "print(\"==========================================================\")\n",
    "\n",
    "print(\"x_train\\n\")\n",
    "print(x_train)\n",
    "print(\"x_test\\n\")\n",
    "print(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)  # (60000, 28, 28)\n",
    "print(x_test.shape)\n",
    "\n",
    "\n",
    "# change data shape\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1] * x_train.shape[2])\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1] * x_test.shape[2])\n",
    "\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n",
      "[7 2 1 ... 4 5 6]\n",
      "(10000, 10)\n",
      "[[0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_test.shape)\n",
    "print(y_test)\n",
    "\n",
    "# change result to one-hot encoding\n",
    "# in tf1, one_hot= True in read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "# took care of it, but here we need to manually convert them\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "print(y_test.shape)\n",
    "print(y_test)\n",
    "\n",
    "# # Consider an array of 5 labels out of a set of 3 classes {0, 1, 2}:\n",
    "# array([0, 2, 1, 2, 0])\n",
    "# `to_categorical` converts this into a matrix with as many columns as there are classes. The number of rows\n",
    "#  stays the same. to_categorical(labels)\n",
    "# array([[ 1.,  0.,  0.],\n",
    "#        [ 0.,  0.,  1.],\n",
    "#        [ 0.,  1.,  0.],\n",
    "#        [ 0.,  0.,  1.],\n",
    "#        [ 1.,  0.,  0.]], dtype=float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n",
      "***************************************************************************************************\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 10)                7850      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "***************************************************************************************************\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-26 16:17:32.912684: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-08-26 16:17:32.912820: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-26 16:17:33.259610: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-08-26 16:17:33.404721: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 3s 5ms/step - loss: 0.6270 - accuracy: 0.8427\n",
      "Epoch 2/30\n",
      "600/600 [==============================] - 3s 6ms/step - loss: 0.3467 - accuracy: 0.9051\n",
      "Epoch 3/30\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 0.3096 - accuracy: 0.9147\n",
      "Epoch 4/30\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.2924 - accuracy: 0.9185\n",
      "Epoch 5/30\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.2821 - accuracy: 0.9217\n",
      "Epoch 6/30\n",
      "600/600 [==============================] - 3s 6ms/step - loss: 0.2748 - accuracy: 0.9231\n",
      "Epoch 7/30\n",
      "600/600 [==============================] - 3s 6ms/step - loss: 0.2698 - accuracy: 0.9245\n",
      "Epoch 8/30\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.2657 - accuracy: 0.9258\n",
      "Epoch 9/30\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 0.2623 - accuracy: 0.9262\n",
      "Epoch 10/30\n",
      "600/600 [==============================] - 3s 6ms/step - loss: 0.2593 - accuracy: 0.9284\n",
      "Epoch 11/30\n",
      "600/600 [==============================] - 3s 6ms/step - loss: 0.2572 - accuracy: 0.9284\n",
      "Epoch 12/30\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.2548 - accuracy: 0.9295\n",
      "Epoch 13/30\n",
      "600/600 [==============================] - 3s 6ms/step - loss: 0.2529 - accuracy: 0.9298\n",
      "Epoch 14/30\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 0.2511 - accuracy: 0.9309\n",
      "Epoch 15/30\n",
      "600/600 [==============================] - 3s 6ms/step - loss: 0.2504 - accuracy: 0.9304\n",
      "Epoch 16/30\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 0.2490 - accuracy: 0.9313\n",
      "Epoch 17/30\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 0.2474 - accuracy: 0.9312\n",
      "Epoch 18/30\n",
      "600/600 [==============================] - 3s 6ms/step - loss: 0.2461 - accuracy: 0.9321\n",
      "Epoch 19/30\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.2451 - accuracy: 0.9323\n",
      "Epoch 20/30\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.2445 - accuracy: 0.9322\n",
      "Epoch 21/30\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 0.2433 - accuracy: 0.9330\n",
      "Epoch 22/30\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 0.2427 - accuracy: 0.9328\n",
      "Epoch 23/30\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 0.2418 - accuracy: 0.9333\n",
      "Epoch 24/30\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 0.2406 - accuracy: 0.9340\n",
      "Epoch 25/30\n",
      "600/600 [==============================] - 3s 6ms/step - loss: 0.2402 - accuracy: 0.9338\n",
      "Epoch 26/30\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 0.2401 - accuracy: 0.9333\n",
      "Epoch 27/30\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 0.2393 - accuracy: 0.9339\n",
      "Epoch 28/30\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 0.2385 - accuracy: 0.9339\n",
      "Epoch 29/30\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 0.2381 - accuracy: 0.9348\n",
      "Epoch 30/30\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.2375 - accuracy: 0.9349\n"
     ]
    }
   ],
   "source": [
    "# Sequential Model\n",
    "# keras의 sequential model은 정의한 다음 아래의 예제 코드처럼 차례로 계층(layer)을 쌓아 나가면 되는 매우 간단한 구조이다.\n",
    "tf.model = tf.keras.Sequential()\n",
    "\n",
    "tf.model.add(tf.keras.layers.Dense(units=10, input_dim=784, activation='softmax'))\n",
    "\n",
    "# Compilation\n",
    "# Sequential 모델을 정의하고 학습하기 전에 .compile() 메서드를 사용하여 학습에 대한 설정을 해줘야한다.\n",
    "#   Optimizer: 최적화 함수를 설정하는 부분이며, 'sgd', 'adam', 'rmsprop' 등 문자열타입으로 설정할 수 있다.\n",
    "#   Loss function: 손실함수를 설정해주는 부분이며, 'categorical_crossentropy', 'mse' 처럼 문자열타입으로 설정할 수 있다.\n",
    "#   Metrics: 모델의 성능을 판정하는데 사용하는 지표 함수이며,['accuracy'] 처럼 리스트 형태로 설정한다.\n",
    "tf.model.compile(loss='categorical_crossentropy', optimizer=tf.optimizers.Adam(0.001), metrics=['accuracy'])\n",
    "\n",
    "\n",
    "print(\"***************************************************************************************************\")\n",
    "tf.model.summary()\n",
    "print(\"***************************************************************************************************\\n\\n\")\n",
    "\n",
    "\n",
    "# learning_rate = 0.001\n",
    "# batch_size = 100\n",
    "# training_epochs = 30\n",
    "# nb_classes = 10\n",
    "\n",
    "\n",
    "# Training\n",
    "# 마지막으로 학습을 하기위해 .fit()에 학습할 데이터를 넣어주고, 에폭(epochs)과 배치크기(batch_size)를 설정해준다.\n",
    "history = tf.model.fit(x_train, y_train, batch_size=batch_size, epochs=training_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/313 [===========>..................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-26 16:19:15.398541: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step\n",
      "Prediction: \n",
      " [[1.01764222e-07 1.49107777e-13 3.78530672e-07 ... 9.95813608e-01\n",
      "  8.85491590e-06 1.78110684e-04]\n",
      " [4.97783913e-05 1.91096410e-06 9.92091775e-01 ... 5.65881568e-21\n",
      "  1.03371567e-05 1.14358654e-17]\n",
      " [3.91083461e-07 9.87801135e-01 7.45791662e-03 ... 7.39117022e-05\n",
      "  1.63689279e-03 1.27808555e-04]\n",
      " ...\n",
      " [3.88562382e-09 1.07516784e-09 2.00762815e-06 ... 1.38462870e-03\n",
      "  8.63794424e-03 1.32458992e-02]\n",
      " [9.31311384e-09 3.43651720e-08 1.44064867e-08 ... 4.72502677e-08\n",
      "  5.26227010e-03 1.38682976e-08]\n",
      " [5.47860246e-08 1.45667739e-15 2.37531567e-05 ... 1.01709387e-16\n",
      "  2.29726460e-09 3.48661936e-13]]\n",
      " 31/313 [=>............................] - ETA: 1s - loss: 0.2764 - accuracy: 0.9244"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-26 16:19:15.888912: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step - loss: 0.2669 - accuracy: 0.9271\n",
      "Accuracy:  0.9271000623703003\n"
     ]
    }
   ],
   "source": [
    "# evaluate test set\n",
    "predictions = tf.model.predict(x_test)\n",
    "print('Prediction: \\n', predictions)\n",
    "x_train\n",
    "\n",
    "# 'output_b': ['mse', 'accuracy']\n",
    "score = tf.model.evaluate(x_test, y_test)\n",
    "print('Accuracy: ', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. NN for MNIST ( ReLU )\n",
    "\n",
    "    * Output Layer 에서는 출력을 0과 1 사이여야하므로 sigmoid function을 이용해야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "random.seed(777)  # for reproducibility\n",
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "training_epochs = 30\n",
    "nb_classes = 10\n",
    "\n",
    "# load_data mnist\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "\n",
    "print(x_train.shape)  # (60000, 28, 28)\n",
    "\n",
    "\n",
    "# change data shape\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1] * x_train.shape[2])\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1] * x_test.shape[2])\n",
    "\n",
    "# one-hot encoding\n",
    "y_train = tf.keras.utils.to_categorical(y_train, nb_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, 256)               200960    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 269,322\n",
      "Trainable params: 269,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mindongjun/miniconda3/envs/tf2/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2022-08-26 16:19:17.980296: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 4s 6ms/step - loss: 2.1001 - accuracy: 0.8987\n",
      "Epoch 2/30\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.4177 - accuracy: 0.9482\n",
      "Epoch 3/30\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.2617 - accuracy: 0.9599\n",
      "Epoch 4/30\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.2074 - accuracy: 0.9645\n",
      "Epoch 5/30\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.1728 - accuracy: 0.9681\n",
      "Epoch 6/30\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.1238 - accuracy: 0.9745\n",
      "Epoch 7/30\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.1123 - accuracy: 0.9755\n",
      "Epoch 8/30\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.0998 - accuracy: 0.9772\n",
      "Epoch 9/30\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.0796 - accuracy: 0.9809\n",
      "Epoch 10/30\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.0742 - accuracy: 0.9816\n",
      "Epoch 11/30\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.0765 - accuracy: 0.9804\n",
      "Epoch 12/30\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.0762 - accuracy: 0.9807\n",
      "Epoch 13/30\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.0714 - accuracy: 0.9812\n",
      "Epoch 14/30\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.0718 - accuracy: 0.9818\n",
      "Epoch 15/30\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.0640 - accuracy: 0.9839\n",
      "Epoch 16/30\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.0692 - accuracy: 0.9830\n",
      "Epoch 17/30\n",
      "600/600 [==============================] - 3s 6ms/step - loss: 0.0526 - accuracy: 0.9864\n",
      "Epoch 18/30\n",
      "600/600 [==============================] - 3s 6ms/step - loss: 0.0628 - accuracy: 0.9844\n",
      "Epoch 19/30\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.0586 - accuracy: 0.9857\n",
      "Epoch 20/30\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.0518 - accuracy: 0.9870\n",
      "Epoch 21/30\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0588 - accuracy: 0.9854\n",
      "Epoch 22/30\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.0523 - accuracy: 0.9873\n",
      "Epoch 23/30\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.0478 - accuracy: 0.9883\n",
      "Epoch 24/30\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.0480 - accuracy: 0.9891\n",
      "Epoch 25/30\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.0604 - accuracy: 0.9861\n",
      "Epoch 26/30\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.0494 - accuracy: 0.9886\n",
      "Epoch 27/30\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.0407 - accuracy: 0.9903\n",
      "Epoch 28/30\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.0455 - accuracy: 0.9901\n",
      "Epoch 29/30\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.0455 - accuracy: 0.9897\n",
      "Epoch 30/30\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.0447 - accuracy: 0.9902\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1406d6280>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sequential Model\n",
    "tf.model = tf.keras.Sequential()\n",
    "\n",
    "\n",
    "tf.model.add(tf.keras.layers.Dense(input_dim=784, units=256, activation='relu'))\n",
    "tf.model.add(tf.keras.layers.Dense(units=256, activation='relu'))\n",
    "tf.model.add(tf.keras.layers.Dense(units=nb_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "# Compilation\n",
    "tf.model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(lr=learning_rate), metrics=['accuracy'])\n",
    "\n",
    "# summary\n",
    "tf.model.summary()\n",
    "\n",
    "# Training\n",
    "tf.model.fit(x_train, y_train, batch_size=batch_size, epochs=training_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 65/313 [=====>........................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-26 16:21:12.010985: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n",
      "index:  3757 actual y:  8 predicted y:  8\n",
      "index:  7304 actual y:  5 predicted y:  5\n",
      "index:  7300 actual y:  7 predicted y:  7\n",
      "index:  6039 actual y:  9 predicted y:  9\n",
      "index:  9429 actual y:  3 predicted y:  3\n",
      "index:  4420 actual y:  5 predicted y:  5\n",
      "index:  5507 actual y:  2 predicted y:  2\n",
      "index:  8809 actual y:  1 predicted y:  1\n",
      "index:  654 actual y:  5 predicted y:  8\n",
      "index:  7302 actual y:  8 predicted y:  8\n",
      " 27/313 [=>............................] - ETA: 1s - loss: 0.2251 - accuracy: 0.9688"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-26 16:21:12.693010: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2210 - accuracy: 0.9727\n",
      "loss:  0.2210409790277481\n",
      "accuracy 0.9727000594139099\n"
     ]
    }
   ],
   "source": [
    "# predict 10 random hand-writing data\n",
    "y_predicted = tf.model.predict(x_test)\n",
    "for x in range(0, 10):\n",
    "    random_index = random.randint(0, x_test.shape[0]-1)\n",
    "    print(\"index: \", random_index,\n",
    "          \"actual y: \", np.argmax(y_test[random_index]),\n",
    "          \"predicted y: \", np.argmax(y_predicted[random_index]))\n",
    "\n",
    "# evaluate test set\n",
    "# 'output_b': ['mse', 'accuracy']\n",
    "evaluation = tf.model.evaluate(x_test, y_test)\n",
    "print('loss: ', evaluation[0])\n",
    "print('accuracy', evaluation[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Xavier for MNIST\n",
    "\n",
    "> * 초기화를 잘 시키는 방법\n",
    "> * The Glorot normal initializer, also called Xavier normal initializer.\n",
    "\n",
    "    1. glorot_normal\n",
    "        Normal Distribution\n",
    "        \" keras.initializers.glorot_normal(seed=None) \"\n",
    "        Glorot 정규분포 초기값 설정기, Xavier 정규분포 초기값 설정기라고 한다.\n",
    "\n",
    "    2. glorot_uniform\n",
    "        Uniform Distribution\n",
    "        \" keras.initializers.glorot_uniform(seed=None) \"\n",
    "        Glorot 균등분포 초기값 설정기, Xavier 균등분포 초기값 설정기라고 한다.\n",
    "\n",
    "    3. HeNormal\n",
    "        \" tf.keras.initializers.HeNormal(seed=None) \"\n",
    "\n",
    "    4. HeUniform\n",
    "        \" tf.keras.initializers.HeUniform(seed=None) \"\n",
    "\n",
    "Activation function으로 ReLU를 사용할 때는 He’s Initialization을 사용하고 sigdmoid나 tanh 등의 S자 모양 곡선일 때는 Xavier Initinaliztion을 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "random.seed(777)  # for reproducibility\n",
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "training_epochs = 30\n",
    "nb_classes = 10\n",
    "\n",
    "# load_data mnist\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "\n",
    "print(x_train.shape)  # (60000, 28, 28)\n",
    "\n",
    "\n",
    "# change data shape\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1] * x_train.shape[2])\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1] * x_test.shape[2])\n",
    "\n",
    "# one-hot encoding\n",
    "y_train = tf.keras.utils.to_categorical(y_train, nb_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 256)               200960    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 269,322\n",
      "Trainable params: 269,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      " 16/600 [..............................] - ETA: 4s - loss: 44.5461 - accuracy: 0.5300  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-26 16:21:15.084988: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 4s 6ms/step - loss: 3.6680 - accuracy: 0.8942\n",
      "Epoch 2/30\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.7351 - accuracy: 0.9447\n",
      "Epoch 3/30\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.4497 - accuracy: 0.9571\n",
      "Epoch 4/30\n",
      "600/600 [==============================] - 3s 6ms/step - loss: 0.3407 - accuracy: 0.9628\n",
      "Epoch 5/30\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.2500 - accuracy: 0.9683\n",
      "Epoch 6/30\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.2270 - accuracy: 0.9706\n",
      "Epoch 7/30\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.1966 - accuracy: 0.9719\n",
      "Epoch 8/30\n",
      "600/600 [==============================] - 3s 6ms/step - loss: 0.1390 - accuracy: 0.9763\n",
      "Epoch 9/30\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.1260 - accuracy: 0.9770\n",
      "Epoch 10/30\n",
      "600/600 [==============================] - 3s 6ms/step - loss: 0.1151 - accuracy: 0.9784\n",
      "Epoch 11/30\n",
      "600/600 [==============================] - 3s 6ms/step - loss: 0.1098 - accuracy: 0.9784\n",
      "Epoch 12/30\n",
      "600/600 [==============================] - 3s 6ms/step - loss: 0.1007 - accuracy: 0.9793\n",
      "Epoch 13/30\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.0969 - accuracy: 0.9798\n",
      "Epoch 14/30\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.0955 - accuracy: 0.9791\n",
      "Epoch 15/30\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.0751 - accuracy: 0.9825\n",
      "Epoch 16/30\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.0916 - accuracy: 0.9799\n",
      "Epoch 17/30\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.0826 - accuracy: 0.9811\n",
      "Epoch 18/30\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.0689 - accuracy: 0.9841\n",
      "Epoch 19/30\n",
      "600/600 [==============================] - 3s 6ms/step - loss: 0.0690 - accuracy: 0.9841\n",
      "Epoch 20/30\n",
      "600/600 [==============================] - 3s 6ms/step - loss: 0.0657 - accuracy: 0.9852\n",
      "Epoch 21/30\n",
      "600/600 [==============================] - 3s 6ms/step - loss: 0.0724 - accuracy: 0.9836\n",
      "Epoch 22/30\n",
      "600/600 [==============================] - 3s 6ms/step - loss: 0.0688 - accuracy: 0.9847\n",
      "Epoch 23/30\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.0660 - accuracy: 0.9860\n",
      "Epoch 24/30\n",
      "600/600 [==============================] - 3s 6ms/step - loss: 0.0569 - accuracy: 0.9872\n",
      "Epoch 25/30\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.0524 - accuracy: 0.9875\n",
      "Epoch 26/30\n",
      "600/600 [==============================] - 3s 6ms/step - loss: 0.0762 - accuracy: 0.9848\n",
      "Epoch 27/30\n",
      "600/600 [==============================] - 3s 6ms/step - loss: 0.0524 - accuracy: 0.9881\n",
      "Epoch 28/30\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.0431 - accuracy: 0.9893\n",
      "Epoch 29/30\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.0371 - accuracy: 0.9914\n",
      "Epoch 30/30\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.0585 - accuracy: 0.9875\n"
     ]
    }
   ],
   "source": [
    "# Sequential Model\n",
    "tf.model = tf.keras.Sequential()\n",
    "# Glorot normal initializer, also called Xavier normal initializer.\n",
    "# see https://www.tensorflow.org/api_docs/python/tf/initializers\n",
    "\n",
    "\n",
    "Xavier = tf.keras.initializers.glorot_normal()\n",
    "He = tf.keras.initializers.he_normal()\n",
    "tf.model.add(tf.keras.layers.Dense(input_dim=784, units=256, kernel_initializer=He, activation='relu'))\n",
    "tf.model.add(tf.keras.layers.Dense(units=256, kernel_initializer=He, activation='relu'))\n",
    "tf.model.add(tf.keras.layers.Dense(units=nb_classes, kernel_initializer=Xavier, activation='softmax'))\n",
    "\n",
    "# Compilation\n",
    "tf.model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(lr=learning_rate), metrics=['accuracy'])\n",
    "\n",
    "# summary\n",
    "tf.model.summary()\n",
    "\n",
    "# Training\n",
    "history = tf.model.fit(x_train, y_train, batch_size=batch_size, epochs=training_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/313 [=========>....................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-26 16:23:01.318781: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n",
      "index:  3757 actual y:  8 predicted y:  3\n",
      "index:  7304 actual y:  5 predicted y:  5\n",
      "index:  7300 actual y:  7 predicted y:  7\n",
      "index:  6039 actual y:  9 predicted y:  9\n",
      "index:  9429 actual y:  3 predicted y:  3\n",
      "index:  4420 actual y:  5 predicted y:  5\n",
      "index:  5507 actual y:  2 predicted y:  2\n",
      "index:  8809 actual y:  1 predicted y:  1\n",
      "index:  654 actual y:  5 predicted y:  5\n",
      "index:  7302 actual y:  8 predicted y:  8\n",
      " 30/313 [=>............................] - ETA: 1s - loss: 0.2654 - accuracy: 0.9677"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-26 16:23:01.907344: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2282 - accuracy: 0.9702\n",
      "loss:  0.22820210456848145\n",
      "accuracy 0.9702000617980957\n"
     ]
    }
   ],
   "source": [
    "# predict 10 random hand-writing data\n",
    "y_predicted = tf.model.predict(x_test)\n",
    "for x in range(0, 10):\n",
    "    random_index = random.randint(0, x_test.shape[0]-1)\n",
    "    print(\"index: \", random_index, \"actual y: \", np.argmax(y_test[random_index]), \"predicted y: \", np.argmax(y_predicted[random_index]))\n",
    "\n",
    "# evaluate test set\n",
    "# 'output_b': ['mse', 'accuracy']\n",
    "evaluation = tf.model.evaluate(x_test, y_test)\n",
    "print('loss: ', evaluation[0])\n",
    "print('accuracy', evaluation[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Deep NN for MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Lab 10 MNIST and Deep learning\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "random.seed(777)  # for reproducibility\n",
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "training_epochs = 30\n",
    "nb_classes = 10\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "\n",
    "print(x_train.shape)  # (60000, 28, 28)\n",
    "\n",
    "\n",
    "# change data shape\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1] * x_train.shape[2])\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1] * x_test.shape[2])\n",
    "\n",
    "\n",
    "# one-hot encoding\n",
    "y_train = tf.keras.utils.to_categorical(y_train, nb_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_7 (Dense)             (None, 512)               401920    \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,195,018\n",
      "Trainable params: 1,195,018\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mindongjun/miniconda3/envs/tf2/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2/600 [..............................] - ETA: 41s - loss: 185.7281 - accuracy: 0.1200 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-26 16:23:04.498152: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 5s 8ms/step - loss: 3.3700 - accuracy: 0.8877\n",
      "Epoch 2/30\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.2692 - accuracy: 0.9480\n",
      "Epoch 3/30\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1717 - accuracy: 0.9609\n",
      "Epoch 4/30\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1315 - accuracy: 0.9682\n",
      "Epoch 5/30\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1113 - accuracy: 0.9712\n",
      "Epoch 6/30\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0916 - accuracy: 0.9755\n",
      "Epoch 7/30\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0978 - accuracy: 0.9743\n",
      "Epoch 8/30\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0800 - accuracy: 0.9778\n",
      "Epoch 9/30\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0636 - accuracy: 0.9812\n",
      "Epoch 10/30\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0670 - accuracy: 0.9808\n",
      "Epoch 11/30\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0633 - accuracy: 0.9821\n",
      "Epoch 12/30\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.0578 - accuracy: 0.9839\n",
      "Epoch 13/30\n",
      "600/600 [==============================] - 6s 10ms/step - loss: 0.0644 - accuracy: 0.9830\n",
      "Epoch 14/30\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.0558 - accuracy: 0.9844\n",
      "Epoch 15/30\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.0535 - accuracy: 0.9855\n",
      "Epoch 16/30\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0525 - accuracy: 0.9858\n",
      "Epoch 17/30\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0460 - accuracy: 0.9876\n",
      "Epoch 18/30\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.0473 - accuracy: 0.9877\n",
      "Epoch 19/30\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0435 - accuracy: 0.9889\n",
      "Epoch 20/30\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0473 - accuracy: 0.9880\n",
      "Epoch 21/30\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0346 - accuracy: 0.9910\n",
      "Epoch 22/30\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.0350 - accuracy: 0.9911\n",
      "Epoch 23/30\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0450 - accuracy: 0.9901\n",
      "Epoch 24/30\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0359 - accuracy: 0.9913\n",
      "Epoch 25/30\n",
      "600/600 [==============================] - 6s 10ms/step - loss: 0.0399 - accuracy: 0.9912\n",
      "Epoch 26/30\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0256 - accuracy: 0.9939\n",
      "Epoch 27/30\n",
      "600/600 [==============================] - 6s 10ms/step - loss: 0.0347 - accuracy: 0.9923\n",
      "Epoch 28/30\n",
      "600/600 [==============================] - 6s 10ms/step - loss: 0.0282 - accuracy: 0.9934\n",
      "Epoch 29/30\n",
      "600/600 [==============================] - 6s 10ms/step - loss: 0.0240 - accuracy: 0.9956\n",
      "Epoch 30/30\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.0345 - accuracy: 0.9927\n"
     ]
    }
   ],
   "source": [
    "# Sequential Model\n",
    "tf.model = tf.keras.Sequential()\n",
    "# Glorot normal initializer, also called Xavier normal initializer.\n",
    "# see https://www.tensorflow.org/api_docs/python/tf/initializers\n",
    "\n",
    "Xavier = tf.keras.initializers.glorot_normal()\n",
    "He = tf.keras.initializers.he_normal()\n",
    "tf.model.add(tf.keras.layers.Dense(input_dim=784, units=512, kernel_initializer=He, activation='relu'))\n",
    "tf.model.add(tf.keras.layers.Dense(units=512, kernel_initializer=He, activation='relu'))\n",
    "tf.model.add(tf.keras.layers.Dense(units=512, kernel_initializer=He, activation='relu'))\n",
    "tf.model.add(tf.keras.layers.Dense(units=512, kernel_initializer=He, activation='relu'))\n",
    "tf.model.add(tf.keras.layers.Dense(units=nb_classes, kernel_initializer=Xavier, activation='softmax'))\n",
    "\n",
    "# Compilation\n",
    "tf.model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(lr=learning_rate), metrics=['accuracy'])\n",
    "\n",
    "# summary\n",
    "tf.model.summary()\n",
    "\n",
    "# Training\n",
    "history = tf.model.fit(x_train, y_train, batch_size=batch_size, epochs=training_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 96/313 [========>.....................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-26 16:25:34.866846: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n",
      "index:  3757 actual y:  8 predicted y:  8\n",
      "index:  7304 actual y:  5 predicted y:  5\n",
      "index:  7300 actual y:  7 predicted y:  7\n",
      "index:  6039 actual y:  9 predicted y:  9\n",
      "index:  9429 actual y:  3 predicted y:  3\n",
      "index:  4420 actual y:  5 predicted y:  5\n",
      "index:  5507 actual y:  2 predicted y:  2\n",
      "index:  8809 actual y:  1 predicted y:  1\n",
      "index:  654 actual y:  5 predicted y:  5\n",
      "index:  7302 actual y:  8 predicted y:  8\n",
      " 18/313 [>.............................] - ETA: 1s - loss: 0.1073 - accuracy: 0.9809"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-26 16:25:35.530693: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step - loss: 0.1291 - accuracy: 0.9794\n",
      "loss:  0.12908074259757996\n",
      "accuracy 0.9794000387191772\n"
     ]
    }
   ],
   "source": [
    "# predict 10 random hand-writing data\n",
    "y_predicted = tf.model.predict(x_test)\n",
    "for x in range(0, 10):\n",
    "    random_index = random.randint(0, x_test.shape[0]-1)\n",
    "    print(\"index: \", random_index, \"actual y: \", np.argmax(y_test[random_index]), \"predicted y: \", np.argmax(y_predicted[random_index]))\n",
    "\n",
    "# evaluate test set\n",
    "# 'output_b': ['mse', 'accuracy']\n",
    "evaluation = tf.model.evaluate(x_test, y_test)\n",
    "print('loss: ', evaluation[0])\n",
    "print('accuracy', evaluation[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Dropout for MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Lab 10 MNIST and Deep learning\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "random.seed(777)  # for reproducibility\n",
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "training_epochs = 30\n",
    "nb_classes = 10\n",
    "\n",
    "# load_data mnist\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "\n",
    "print(x_train.shape)  # (60000, 28, 28)\n",
    "\n",
    "\n",
    "# change data shape\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1] * x_train.shape[2])\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1] * x_test.shape[2])\n",
    "\n",
    "# one-hot encoding\n",
    "y_train = tf.keras.utils.to_categorical(y_train, nb_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,195,018\n",
      "Trainable params: 1,195,018\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "  7/600 [..............................] - ETA: 5s - loss: 220.3583 - accuracy: 0.1671  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-26 16:25:38.191503: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 7s 11ms/step - loss: 7.9183 - accuracy: 0.7425\n",
      "Epoch 2/30\n",
      "600/600 [==============================] - 6s 11ms/step - loss: 0.6701 - accuracy: 0.8511\n",
      "Epoch 3/30\n",
      "600/600 [==============================] - 7s 11ms/step - loss: 0.4004 - accuracy: 0.8948\n",
      "Epoch 4/30\n",
      "600/600 [==============================] - 6s 10ms/step - loss: 0.3013 - accuracy: 0.9184\n",
      "Epoch 5/30\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 0.2538 - accuracy: 0.9308\n",
      "Epoch 6/30\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.2216 - accuracy: 0.9400\n",
      "Epoch 7/30\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.1986 - accuracy: 0.9440\n",
      "Epoch 8/30\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.1897 - accuracy: 0.9473\n",
      "Epoch 9/30\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1788 - accuracy: 0.9520\n",
      "Epoch 10/30\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.1757 - accuracy: 0.9528\n",
      "Epoch 11/30\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.1646 - accuracy: 0.9571\n",
      "Epoch 12/30\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.1725 - accuracy: 0.9563\n",
      "Epoch 13/30\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.1547 - accuracy: 0.9609\n",
      "Epoch 14/30\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.1524 - accuracy: 0.9606\n",
      "Epoch 15/30\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.1578 - accuracy: 0.9615\n",
      "Epoch 16/30\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.1482 - accuracy: 0.9620\n",
      "Epoch 17/30\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.1303 - accuracy: 0.9678\n",
      "Epoch 18/30\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.1390 - accuracy: 0.9656\n",
      "Epoch 19/30\n",
      "600/600 [==============================] - 7s 11ms/step - loss: 0.1353 - accuracy: 0.9674\n",
      "Epoch 20/30\n",
      "600/600 [==============================] - 8s 13ms/step - loss: 0.1453 - accuracy: 0.9666\n",
      "Epoch 21/30\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.1301 - accuracy: 0.9683\n",
      "Epoch 22/30\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.1262 - accuracy: 0.9702\n",
      "Epoch 23/30\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.1258 - accuracy: 0.9699\n",
      "Epoch 24/30\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.1152 - accuracy: 0.9726\n",
      "Epoch 25/30\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.1147 - accuracy: 0.9727\n",
      "Epoch 26/30\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1047 - accuracy: 0.9746\n",
      "Epoch 27/30\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.1174 - accuracy: 0.9725\n",
      "Epoch 28/30\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 0.1274 - accuracy: 0.9716\n",
      "Epoch 29/30\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.1104 - accuracy: 0.9739\n",
      "Epoch 30/30\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.1153 - accuracy: 0.9745\n"
     ]
    }
   ],
   "source": [
    "# Sequential Model\n",
    "tf.model = tf.keras.Sequential()\n",
    "# Glorot normal initializer, also called Xavier normal initializer.\n",
    "# see https://www.tensorflow.org/api_docs/python/tf/initializers\n",
    "\n",
    "\n",
    "\n",
    "# 0.7(70%)에 해당하는 노드들만 남겨두고 다 지워버리는 것\n",
    "# Float between 0 and 1. Fraction of the input units to drop.\n",
    "drop_rate = 0.3\n",
    "\n",
    "Xavier = tf.keras.initializers.glorot_normal()\n",
    "He = tf.keras.initializers.he_normal()\n",
    "\n",
    "tf.model.add(tf.keras.layers.Dense(input_dim=784, units=512, kernel_initializer=He, activation='relu'))\n",
    "tf.model.add(tf.keras.layers.Dropout(drop_rate))\n",
    "\n",
    "tf.model.add(tf.keras.layers.Dense(units=512, kernel_initializer=He, activation='relu'))\n",
    "tf.model.add(tf.keras.layers.Dropout(drop_rate))\n",
    "\n",
    "tf.model.add(tf.keras.layers.Dense(units=512, kernel_initializer=He, activation='relu'))\n",
    "tf.model.add(tf.keras.layers.Dropout(drop_rate))\n",
    "\n",
    "tf.model.add(tf.keras.layers.Dense(units=512, kernel_initializer=He, activation='relu'))\n",
    "tf.model.add(tf.keras.layers.Dropout(drop_rate))\n",
    "\n",
    "tf.model.add(tf.keras.layers.Dense(units=nb_classes, kernel_initializer=Xavier, activation='softmax'))\n",
    "\n",
    "\n",
    "# Compilation\n",
    "tf.model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(lr=learning_rate), metrics=['accuracy'])\n",
    "\n",
    "# summary\n",
    "tf.model.summary()\n",
    "\n",
    "# Training\n",
    "history = tf.model.fit(x_train, y_train, batch_size=batch_size, epochs=training_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 88/313 [=======>......................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-26 16:28:25.663004: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n",
      "index:  3757 actual y:  8 predicted y:  3\n",
      "index:  7304 actual y:  5 predicted y:  5\n",
      "index:  7300 actual y:  7 predicted y:  7\n",
      "index:  6039 actual y:  9 predicted y:  9\n",
      "index:  9429 actual y:  3 predicted y:  3\n",
      "index:  4420 actual y:  5 predicted y:  5\n",
      "index:  5507 actual y:  2 predicted y:  2\n",
      "index:  8809 actual y:  1 predicted y:  1\n",
      "index:  654 actual y:  5 predicted y:  5\n",
      "index:  7302 actual y:  8 predicted y:  8\n",
      " 19/313 [>.............................] - ETA: 1s - loss: 0.0823 - accuracy: 0.9770"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-26 16:28:26.320604: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step - loss: 0.1415 - accuracy: 0.9762\n",
      "loss:  0.1415245234966278\n",
      "accuracy 0.9762000441551208\n"
     ]
    }
   ],
   "source": [
    "# predict 10 random hand-writing data\n",
    "y_predicted = tf.model.predict(x_test)\n",
    "for x in range(0, 10):\n",
    "    random_index = random.randint(0, x_test.shape[0]-1)\n",
    "    print(\"index: \", random_index, \"actual y: \", np.argmax(y_test[random_index]), \"predicted y: \", np.argmax(y_predicted[random_index]))\n",
    "\n",
    "# evaluate test set\n",
    "# 'output_b': ['mse', 'accuracy']\n",
    "evaluation = tf.model.evaluate(x_test, y_test)\n",
    "print('loss: ', evaluation[0])\n",
    "print('accuracy', evaluation[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 ('tf2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7c0a6cafd1d3578584654591a2ba703dcd0177f375c399a413abbbba46e2d79b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
